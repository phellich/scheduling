{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOCAL = 'Avenches'\n",
    "LOCAL = 'Lausanne'\n",
    "FRACT_ACT = 1\n",
    "FRACT_POP = 1\n",
    "TIME_INTERVAL = 5 # ou 10\n",
    "activity_types = ['work', 'education', 'leisure', 'shop']\n",
    "HORIZON = round(24*60/TIME_INTERVAL) + 1\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generic functions :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sample(df, column, fraction):\n",
    "    \"\"\"\n",
    "    Perform stratified sampling on df based on column.\n",
    "    :param df: Input dataframe\n",
    "    :param column: Column name for stratification\n",
    "    :param fraction: Fraction of rows to sample from each group\n",
    "    :return: Sampled dataframe\n",
    "    \"\"\"\n",
    "    return df.groupby(column).apply(lambda x: x.sample(frac=fraction)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_horizon(t):\n",
    "    \"\"\" Help to round a time to 5m intervals \"\"\"\n",
    "    # Convert datetime.time to datetime.datetime for calculations\n",
    "    dt = datetime.combine(datetime.today(), t)\n",
    "    \n",
    "    # Find the number of seconds since midnight\n",
    "    seconds_since_midnight = (dt - dt.replace(hour=0, minute=0, second=0, microsecond=0)).seconds\n",
    "\n",
    "    # Round to the closest 5 minutes (300 seconds)\n",
    "    rounded_seconds = round(seconds_since_midnight / (TIME_INTERVAL*60)) * TIME_INTERVAL*60\n",
    "    rounded_dt = dt.replace(hour=0, minute=0, second=0) + timedelta(seconds=rounded_seconds)\n",
    "\n",
    "    return rounded_dt.time()\n",
    "\n",
    "def time_to_horizon_interval(t):\n",
    "    \"\"\" Return time horizon corresponding to a timestamp \"\"\"\n",
    "    rounded_time = round_to_horizon(t)\n",
    "    \n",
    "    # Convert datetime.time to datetime.datetime for calculations\n",
    "    dt = datetime.combine(datetime.today(), rounded_time)\n",
    "    \n",
    "    # Get total minutes since midnight\n",
    "    minutes_since_midnight = (dt - dt.replace(hour=0, minute=0, second=0)).seconds // 60\n",
    "\n",
    "    # Convert total minutes to horizon intervals (5 minute intervals)\n",
    "    horizon_interval = minutes_since_midnight // TIME_INTERVAL\n",
    "\n",
    "    return horizon_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data and filter the irrelevants columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_file = 'Data/1_Original/vaud_activities.csv.gz'\n",
    "population_file = 'Data/1_Original/vaud_population.csv.gz'\n",
    "trip_file = 'Data/1_Original/vaud_trips.csv.gz'\n",
    "\n",
    "def read_gzipped_csv(file_path):\n",
    "    with gzip.open(file_path, 'rt') as file:\n",
    "        df = pd.read_csv(file)\n",
    "    return df\n",
    "\n",
    "activity_vaud = read_gzipped_csv(activity_file)[['id', 'type', 'facility', 'x', 'y', 'start_time', 'end_time']]\n",
    "population_vaud = read_gzipped_csv(population_file)[['id', 'local', 'age', 'employed', 'home_x', 'home_y']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the population by the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_local = population_vaud[population_vaud['local'] == LOCAL] \n",
    "# print(len(population_local))\n",
    "# population_local.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the filtered population to extract activities of the same city. Also count the activities by type in this city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the count of facilities by types in Lausanne :         type  facility\n",
      "0  education       220\n",
      "1       home     70975\n",
      "2    leisure      6277\n",
      "3       shop      3177\n",
      "4       work     13173\n"
     ]
    }
   ],
   "source": [
    "population_local_ids = population_local['id'].unique()\n",
    "activity_local = activity_vaud[activity_vaud['id'].isin(population_local_ids)]\n",
    "activity_local_filt_nowork = activity_local[~activity_local['type'].isin(['other', 'pt interaction', 'home', 'work'])] \n",
    "activity_local_filt_for_count = activity_local[~activity_local['type'].isin(['other', 'pt interaction'])] \n",
    "count_act_by_types = activity_local_filt_for_count.groupby('type')['facility'].nunique().reset_index()\n",
    "print(f\"Here's the count of facilities by types in {LOCAL} : {count_act_by_types}\")\n",
    "# print(len(activity_local_filt))\n",
    "# activity_local_filt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the activities of this city by keeping the proportion between each type (stratified sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# peut etre associer un seed pour avoir toujours le meme resultat ? \n",
    "# Attention : stratified sampling != proportional sampling \n",
    "activity_local_filt_sampled = stratified_sample(activity_local_filt_nowork, column='type', fraction=FRACT_ACT) # 0.001 to compare exact / heuristic\n",
    "# activity_local_filt_sampled.drop(columns=['start_time', 'end_time'], inplace=True)\n",
    "# print(len(activity_local_filt))\n",
    "# print(len(activity_local_filt_sampled))\n",
    "# count_act_by_types_sampled = activity_local_filt_sampled.groupby('type')['facility'].nunique().reset_index()\n",
    "# print(f\"Here's the count of facilities by types in the sample : {count_act_by_types_sampled}\")\n",
    "# activity_local_filt_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new columns for each activity with their caracterics (anticipate initialization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = 00:00 // 288 = 24:00 (total len = 289)\n",
    "# Code to fix the following values for each activity type : \n",
    "    # t1 = earliest time to start\n",
    "    # t2 = latest time to start\n",
    "    # t3 = max duration\n",
    "    # min duration\n",
    "    # des duration\n",
    "\n",
    "for i, row in activity_local_filt_sampled.iterrows():\n",
    "    type_ = row['type']\n",
    "    match type_: # need python >=3.10\n",
    "        case 'education':\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 1\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 7*60/TIME_INTERVAL # 7h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 23*60/TIME_INTERVAL # 23h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 10*60/TIME_INTERVAL # 10h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 10/TIME_INTERVAL # 10m\n",
    "        case 'leisure':\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 3\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 7*60/TIME_INTERVAL # 7h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 23*60/TIME_INTERVAL # 23h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 10*60/TIME_INTERVAL # 10h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 10/TIME_INTERVAL # 10m\n",
    "        case 'shop':\n",
    "            activity_local_filt_sampled.at[i, 'group'] = 4\n",
    "            activity_local_filt_sampled.at[i, 'earliest_start'] = 7*60/TIME_INTERVAL # 7h\n",
    "            activity_local_filt_sampled.at[i, 'latest_start'] = 23*60/TIME_INTERVAL # 23h\n",
    "            activity_local_filt_sampled.at[i, 'max_duration'] = 10*60/TIME_INTERVAL # 10h\n",
    "            activity_local_filt_sampled.at[i, 'min_duration'] = 10/TIME_INTERVAL # 10m\n",
    "    # # work\n",
    "    # activities_array[num_activities-3].id = num_activities-3\n",
    "    # activities_array[num_activities-3].x = individual['work_x']\n",
    "    # activities_array[num_activities-3].y = individual['work_y']\n",
    "    # activities_array[num_activities-3].earliest_start = round(5*60/TIME_INTERVAL) # 5h\n",
    "    # activities_array[num_activities-3].latest_start = round(23*60/TIME_INTERVAL) # 23h\n",
    "    # activities_array[num_activities-3].max_duration = round(12*60/TIME_INTERVAL) # 12h\n",
    "    # activities_array[num_activities-3].min_duration = round(10/TIME_INTERVAL) # 10m\n",
    "    # activities_array[num_activities-3].group = 2\n",
    "    # activities_array[num_activities-3].des_duration = individual['work_dur']\n",
    "    # activities_array[num_activities-3].des_start_time = individual['work_start']\n",
    "            \n",
    "int_columns = ['earliest_start', 'latest_start', 'max_duration', 'min_duration', 'x', 'y', 'group']\n",
    "activity_local_filt_sampled[int_columns] = activity_local_filt_sampled[int_columns].astype(int) \n",
    "# Proof that we have a activity id : \n",
    "# print(len(activity_local_filt_sampled))\n",
    "# print(activity_local_filt_sampled.index.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the individuals among the city inhabitants and converts home coordinates in `int`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_local_sample = population_local.sample(frac = FRACT_POP)\n",
    "# print(len(population_local))\n",
    "# print(len(population_local_sample))\n",
    "# population_local_sample.head(1)\n",
    "# activity_local_filt_sampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter invalid times (hours < 24) & Convert time object in terms of horizons  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "activity_local_filt = activity_local[~activity_local['type'].isin(['other', 'pt interaction', 'home'])] \n",
    "\n",
    "# Assuming 'start_time' and 'end_time' are in a format recognized by pandas (like 'HH:MM:SS')\n",
    "activity_local_filt['start_time'] = pd.to_timedelta(activity_local_filt['start_time'].astype(str))\n",
    "activity_local_filt['end_time'] = pd.to_timedelta(activity_local_filt['end_time'].astype(str))\n",
    "\n",
    "# Filter out any NaT values or times that are not within the correct range\n",
    "# For example, checking that 'start_time' and 'end_time' are less than 24 hours\n",
    "activity_local_filt = activity_local_filt[\n",
    "    (activity_local_filt['start_time'] < pd.Timedelta('1 days')) &\n",
    "    (activity_local_filt['end_time'] < pd.Timedelta('1 days'))\n",
    "]\n",
    "\n",
    "# Convert 'start_time' and 'end_time' to 'datetime.time' if they are within a single day.\n",
    "activity_local_filt['start_time'] = activity_local_filt['start_time'].apply(\n",
    "    lambda x: (datetime.min + x).time() if isinstance(x, pd.Timedelta) and x < pd.Timedelta(days=1) else x\n",
    ")\n",
    "activity_local_filt['end_time'] = activity_local_filt['end_time'].apply(\n",
    "    lambda x: (datetime.min + x).time() if isinstance(x, pd.Timedelta) and x < pd.Timedelta(days=1) else x\n",
    ")\n",
    "\n",
    "# print(activity_local_filt.head())\n",
    "\n",
    "activity_local_filt['start_time_interval'] = activity_local_filt['start_time'].apply(time_to_horizon_interval)\n",
    "activity_local_filt['end_time_interval'] = activity_local_filt['end_time'].apply(time_to_horizon_interval)\n",
    "activity_local_filt['duration_interval'] = activity_local_filt['end_time_interval'] - activity_local_filt['start_time_interval']\n",
    "\n",
    "# print(len(activity_local_filt))\n",
    "# activity_local_filt.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each individual, and for each activity type, add starting time and duration preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_range1 = population_local[(population_local['age'] >= 0) & (population_local['age'] <= 18)]\n",
    "id_range2_emp = population_local[(population_local['age'] >= 19) & (population_local['age'] <= 35) & (population_local['employed'] == True)]\n",
    "id_range3_emp = population_local[(population_local['age'] >= 36) & (population_local['age'] <= 65) & (population_local['employed'] == True)]\n",
    "id_range4_emp = population_local[(population_local['age'] >= 66) & (population_local['age'] <= 100) & (population_local['employed'] == True)]\n",
    "id_range2_unemp = population_local[(population_local['age'] >= 21) & (population_local['age'] <= 40) & (population_local['employed'] == False)]\n",
    "id_range3_unemp = population_local[(population_local['age'] >= 41) & (population_local['age'] <= 65) & (population_local['employed'] == False)]\n",
    "id_range4_unemp = population_local[(population_local['age'] >= 66) & (population_local['age'] <= 100) & (population_local['employed'] == False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distributions(sub_population, activity_local_filt):\n",
    "    '''Fonction pour calculer la distribution des intervalles de temps de début et de durée\n",
    "    Returns a dictionary distributions['start_time_interval'] = count // distributions['duration_interval'] = count'''\n",
    "    distributions = {}\n",
    "    sub_population_ids = sub_population['id'].unique()\n",
    "    filtered_activities = activity_local_filt[activity_local_filt['id'].isin(sub_population_ids)]\n",
    "\n",
    "    for activity_type in filtered_activities['type'].unique():\n",
    "        activity_data = filtered_activities[filtered_activities['type'] == activity_type]\n",
    "        start_dist = activity_data['start_time_interval'].value_counts(normalize=True)\n",
    "        duration_dist = activity_data['duration_interval'].value_counts(normalize=True)\n",
    "        distributions[activity_type] = {'start': start_dist, 'duration': duration_dist}\n",
    "    \n",
    "    return distributions\n",
    "\n",
    "def get_subpopulation_id(person):\n",
    "    age, employed = person['age'], person['employed']\n",
    "    if age <= 18:\n",
    "        return 'range1'\n",
    "    elif age <= 35:\n",
    "        return 'range2_emp' if employed else 'range2_unemp'\n",
    "    elif age <= 65:\n",
    "        return 'range3_emp' if employed else 'range3_unemp'\n",
    "    else:\n",
    "        return 'range4_emp' if employed else 'range4_unemp'\n",
    "\n",
    "# Calculer les distributions pour chaque sous-population\n",
    "distributions = {\n",
    "    'range1': calculate_distributions(id_range1, activity_local_filt),\n",
    "    'range2_emp': calculate_distributions(id_range2_emp, activity_local_filt),\n",
    "    'range3_emp': calculate_distributions(id_range3_emp, activity_local_filt),\n",
    "    'range4_emp': calculate_distributions(id_range4_emp, activity_local_filt),\n",
    "    'range2_unemp': calculate_distributions(id_range2_unemp, activity_local_filt),\n",
    "    'range3_unemp': calculate_distributions(id_range3_unemp, activity_local_filt),\n",
    "    'range4_unemp': calculate_distributions(id_range4_unemp, activity_local_filt),\n",
    "}\n",
    "# print(distributions['range2_emp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139392/139392 [00:39<00:00, 3503.19it/s]\n"
     ]
    }
   ],
   "source": [
    "# # ARE THERE HOMELESS PEOPLE ? NO\n",
    "# # get id of pop\n",
    "# all = activity_vaud['id']\n",
    "# # get id of pop with a home\n",
    "# homers = activity_vaud[activity_vaud['type']=='home']['id']\n",
    "# # difference between the two : people who have no homes\n",
    "# print(set(all) - set(homers))\n",
    "\n",
    "activity_local_homes = activity_local[activity_local['type']=='home']\n",
    "def get_home_id(row):\n",
    "    homeid = activity_local_homes[activity_local_homes['id']==row['id']]['facility'].iloc[0]\n",
    "    if homeid is None: \n",
    "        print(f\"HOMEID IS NULL {homeid}\")\n",
    "    return homeid\n",
    "    \n",
    "population_local_sample.loc[:, 'homeid'] = population_local_sample.progress_apply(lambda row: get_home_id(row), axis=1)\n",
    "# population_local_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139392/139392 [14:28<00:00, 160.47it/s]\n"
     ]
    }
   ],
   "source": [
    "# NEW\n",
    "\n",
    "column_names = [(f'{activity_type}_start', f'{activity_type}_dur') for activity_type in activity_types]\n",
    "\n",
    "for col_start, col_dur in column_names:\n",
    "    population_local_sample[col_start] = 0\n",
    "    population_local_sample[col_dur] = 0\n",
    "\n",
    "def assign_activity_values(row):\n",
    "    subpop_id = get_subpopulation_id(row)\n",
    "    \n",
    "    for activity_type, (col_start, col_dur) in zip(activity_types, column_names):\n",
    "        dist = distributions[subpop_id].get(activity_type, {'start': pd.Series(), 'duration': pd.Series()})\n",
    "        \n",
    "        if dist['start'].empty or dist['duration'].empty or (subpop_id == 'range1' and activity_type == 'work'):\n",
    "            chosen_start = 0\n",
    "            chosen_duration = 0\n",
    "        else:\n",
    "            chosen_start = np.random.choice(dist['start'].index, p=dist['start'].values)\n",
    "            chosen_duration = np.random.choice(dist['duration'].index, p=dist['duration'].values)\n",
    "        \n",
    "        row[col_start] = chosen_start\n",
    "        row[col_dur] = chosen_duration\n",
    "    return row\n",
    "\n",
    "population_local_sample = population_local_sample.progress_apply(assign_activity_values, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a random work facility for each individual according to the workplace distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13173 work facilities in Lausanne\n"
     ]
    }
   ],
   "source": [
    "df_work_facilities = activity_local[activity_local['type'] == 'work']\n",
    "print(f\"There are {df_work_facilities['facility'].nunique()} work facilities in {LOCAL}\")\n",
    "work_facilities_count = df_work_facilities.groupby('facility')['id'].count()\n",
    "\n",
    "# Créer un DataFrame résumé avec les coordonnées moyennes pour chaque établissement\n",
    "facility_coords = df_work_facilities.groupby('facility')[['x', 'y']].mean()\n",
    "\n",
    "# Créer le dictionnaire pour les coordonnées x et y des établissements\n",
    "facility_coords_dict = facility_coords.to_dict('index')\n",
    "\n",
    "# Choisir un établissement pour chaque individu dans l'échantillon\n",
    "N = len(population_local_sample)\n",
    "facilities = work_facilities_count.index.tolist()\n",
    "workers = work_facilities_count.tolist()\n",
    "chosen_facilities = random.choices(facilities, weights=workers, k=N)\n",
    "\n",
    "# Assigner les coordonnées x, y et l'ID de l'établissement choisi\n",
    "population_local_sample['work_id'] = chosen_facilities\n",
    "population_local_sample['work_x'] = [facility_coords_dict[facility]['x'] for facility in chosen_facilities]\n",
    "population_local_sample['work_y'] = [facility_coords_dict[facility]['y'] for facility in chosen_facilities]\n",
    "# population_local_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the final preprocessed dataframes into .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_columns_2 = ['home_x', 'home_y', 'work_x', 'work_y', 'work_id', 'work_start', 'shop_start', 'leisure_start', 'education_start',\n",
    "                 'work_dur', 'shop_dur', 'leisure_dur', 'education_dur'] \n",
    "population_local_sample[int_columns_2] = population_local_sample[int_columns_2].astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_local_filt_sampled.drop(['start_time', 'end_time'], axis=1, inplace=True)\n",
    "activity_local_filt_sampled.to_csv(f'Data/2_PreProcessed/activities_{LOCAL}.csv', index=False)\n",
    "population_local_sample.to_csv(f'Data/2_PreProcessed/population_{LOCAL}.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create 2 other files for 10m preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = ['earliest_start','latest_start','max_duration','min_duration']\n",
    "# for c in col:\n",
    "#     activity_local_filt_sampled[c] = round(activity_local_filt_sampled[c]/2)\n",
    "\n",
    "# activity_local_filt_sampled[col] = activity_local_filt_sampled[col].astype(int) \n",
    "# activity_local_filt_sampled.drop(['start_time', 'end_time'], axis=1).to_csv(f'Data/2_PreProcessed/activity_10m.csv', index=False)\n",
    "\n",
    "# for activity_type in activity_types:\n",
    "#     population_local_sample[f'{activity_type}_start'] = round(population_local_sample[f'{activity_type}_start']/2)\n",
    "#     population_local_sample[f'{activity_type}_dur'] = round(population_local_sample[f'{activity_type}_dur']/2)\n",
    "\n",
    "# int_columns_2 = ['home_x', 'home_y', 'work_x', 'work_y', 'work_id', 'work_start', 'shop_start', 'leisure_start', 'education_start',\n",
    "#                  'work_dur', 'shop_dur', 'leisure_dur', 'education_dur'] \n",
    "# population_local_sample[int_columns_2] = population_local_sample[int_columns_2].astype(int) \n",
    "# population_local_sample.to_csv(f'Data/2_PreProcessed/population_10m.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where any of the required columns have NaNs\n",
    "population_local_sample.dropna(subset=['home_x', 'home_y', 'work_x', 'work_y'], inplace=True)\n",
    "\n",
    "# Now apply the distance calculation\n",
    "population_local_sample['distance_H2W'] = np.sqrt(\n",
    "    (population_local_sample['home_x'] - population_local_sample['work_x'])**2 +\n",
    "    (population_local_sample['home_y'] - population_local_sample['work_y'])**2\n",
    ")\n",
    "population_local_sample['distance_H2W'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the distribution of distance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(population_local_sample['distance_H2W'], bins=30, alpha=0.7, color='blue')\n",
    "plt.title('OURS Distribution of Distance from Home to Work')\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the boxplot of the distance\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(population_local_sample['distance_H2W'].dropna(), vert=False)  # Drop NA values for boxplot\n",
    "plt.title('Boxplot of Distance from Home to Work')\n",
    "plt.xlabel('Distance')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = df_work_facilities.merge(population_local, how='left', on='id')\n",
    "# merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where any of the required columns have NaNs\n",
    "merged.dropna(subset=['home_x', 'home_y', 'x', 'y'], inplace=True)\n",
    "\n",
    "# Now apply the distance calculation\n",
    "merged['distance_H2W'] = np.sqrt(\n",
    "    (merged['home_x'] - merged['x'])**2 +\n",
    "    (merged['home_y'] - merged['y'])**2\n",
    ")\n",
    "merged['distance_H2W'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of distance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(merged['distance_H2W'], bins=100, alpha=0.7, color='blue')\n",
    "plt.title('REAL Distribution of Distance from Home to Work')\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlim((0, 50000))\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot the boxplot of the distance\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(merged['distance_H2W'].dropna(), vert=False)  # Drop NA values for boxplot\n",
    "plt.title('Boxplot of Distance from Home to Work')\n",
    "plt.xlabel('Distance')\n",
    "plt.xlim((0, 50000))\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_a1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
